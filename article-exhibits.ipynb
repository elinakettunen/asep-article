{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import exit\n",
    "\n",
    "# clean output directory every time\n",
    "import shutil\n",
    "try: shutil.rmtree('out')\n",
    "except FileNotFoundError: pass\n",
    "\n",
    "from pathlib import Path\n",
    "Path('out').mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data files are exactly as received from MIRA Helsinki Study. This code does not write to these files.\n",
    "data_master = 'data/mira/MIRA Master file 180527.sav'\n",
    "data_lab = 'data/mira/HUSLAB Data final_WithMixedVegans.txt'\n",
    "data_intakes = 'data/mira/muuttujat_analyysiin.txt'\n",
    "data_thl = 'data/mira/growth-curves.tsv'\n",
    "data_questionnaire = 'data/mira/data huoltajan tausta 171106.sav'\n",
    "data_food_record = 'data/mira/radata.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#declare common column names as variables\n",
    "ldl = 'fP-Kol-LDL (mmol/l)'\n",
    "tc = 'fP-Kol (mmol/l)'\n",
    "serum_lipids = [\n",
    "    tc,\n",
    "    ldl, \n",
    "    'fP-Kol-HDL (mmol/l)', \n",
    "    'fP-Trigly (mmol/l)'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in mira study data\n",
    "lab_results = pd.read_csv(data_lab, sep='\\t', decimal=\",\")\n",
    "intakes = pd.read_csv(data_intakes, sep='\\t')\n",
    "\n",
    "subjects_all = intakes.merge(lab_results, how='left', on='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify diets\n",
    "g6_map = {\n",
    "    'Pesco-vegetarian': 'Vegetarian',\n",
    "    'Vegan': 'Vegan',\n",
    "    'Control': 'Omnivore',\n",
    "    'Control (vegan in daycare)': 'Omnivore',\n",
    "    'Vegetarian': 'Vegetarian',\n",
    "}\n",
    "diet_class = 'diet classification'\n",
    "diet_classes = ['Vegan','Vegetarian','Omnivore']\n",
    "\n",
    "s = subjects_all.Group4.map(g6_map)\n",
    "s = s.fillna('Omnivore')\n",
    "\n",
    "subjects_all.insert(6,diet_class,s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one participant was reported to be vegan, but had consumed dairy products\n",
    "subjects_all.loc[subjects_all.ID==402,diet_class] = 'Vegetarian'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_all[['ID','Group2','Group3','Group4',diet_class]].to_csv('out/subject_grouping.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Finnish THL curves for child BMI SDS\n",
    "\n",
    "curves = pd.read_csv(data_thl,sep='\\t',decimal=',')\n",
    "curves.columns = [c.lower() for c in curves.columns]\n",
    "\n",
    "# no curve for children under two, fill in with a linear extrapolation\n",
    "\n",
    "def fill_start_with_linear_extrapolation(s):\n",
    "    i = s.first_valid_index()\n",
    "    x1 = s.loc[i]\n",
    "    x2 = s.loc[2*i]\n",
    "    x0 = x1 - (x2-x1)\n",
    "    return pd.concat(\n",
    "        [\n",
    "            pd.Series(np.linspace(x0,x1,i)),\n",
    "            s[i:]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "for c in 'bmi_mean_m','bmi_sd_m','bmi_nu_m','bmi_mean_f','bmi_sd_f','bmi_nu_f':\n",
    "    s = curves[c]\n",
    "    s2 = fill_start_with_linear_extrapolation(s)\n",
    "    curves.insert(\n",
    "        curves.columns.get_loc(c)+1,\n",
    "        c+'_filled',\n",
    "        s2\n",
    "    )\n",
    "\n",
    "# BMISDS = ((BMIlaskettu / muBMI) ^ nuBMI – 1) / (nuBMI × sigmaBMI)\n",
    "def translate_sex(s):\n",
    "    if s in ('M','m'): return 'm'\n",
    "    if s in ('N','n','F','f'): return 'f'\n",
    "    return None\n",
    "\n",
    "def bmi_sds(weight,height,age,sex):\n",
    "    # NaN check\n",
    "    if age != age: return None\n",
    "    \n",
    "    age = round(age,2)\n",
    "    sex = translate_sex(sex)\n",
    "\n",
    "    bmi = weight/height**2\n",
    "\n",
    "    row = curves[curves.age==age].iloc[0]\n",
    "    mu_bmi = row['bmi_mean_'+sex+'_filled']\n",
    "    nu_bmi = row['bmi_nu_'+sex+'_filled']\n",
    "    sigma_bmi = row['bmi_sd_'+sex+'_filled']\n",
    "\n",
    "    bmi_sds = ((bmi/mu_bmi)**nu_bmi - 1) / (nu_bmi * sigma_bmi)\n",
    "\n",
    "    return bmi_sds\n",
    "\n",
    "bmi_sds = subjects_all.apply(\n",
    "    lambda row: bmi_sds(\n",
    "        row.Weight,\n",
    "        row.Height/100,\n",
    "        row.AntAge, #row.Bage,\n",
    "        row.Sex\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "subjects_all.insert(12,'bmi_sds',bmi_sds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify BMI by SDS\n",
    "\n",
    "def is_female(s):\n",
    "    return s in ('N','n','F','f')\n",
    "\n",
    "def is_male(s):\n",
    "    return s in ('M','m')\n",
    "\n",
    "def classify_bmi_sds(bmi_sds,sex):\n",
    "    if is_female(sex):\n",
    "        if bmi_sds < -2.2187: return 'Significantly underweight'\n",
    "        if bmi_sds < -1.6482: return 'Underweight'\n",
    "        if bmi_sds > 2.7600: return 'Severely Obese'\n",
    "        if bmi_sds > 2.1065: return 'Obese'\n",
    "        if bmi_sds > 1.1629: return 'Overweight'\n",
    "        return 'Normal'\n",
    "    if is_male(sex):\n",
    "        if bmi_sds < -2.3456: return 'Significantly underweight'\n",
    "        if bmi_sds < -1.8344: return 'Underweight'\n",
    "        if bmi_sds > 2.3600: return 'Severely Obese'\n",
    "        if bmi_sds > 1.7016: return 'Obese'\n",
    "        if bmi_sds > 0.7784: return 'Overweight'\n",
    "        return 'Normal'\n",
    "    return None\n",
    "\n",
    "bmi_class = subjects_all.apply(\n",
    "    lambda row: classify_bmi_sds(\n",
    "        row.bmi_sds,\n",
    "        row.Sex\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "subjects_all.insert(13,'bmi_class',bmi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_all['ENER_kcal_per_d'] = subjects_all.ENERJ_per_d / 4.184"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this file contains the weight proportion of animal source ingredients in a food item/dish as calculated or estimated by a researcher\n",
    "# links to Fineli food items for foods recorded using Fineli codes\n",
    "data_food_animal_proportion = 'data/food-animal-proportion.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_records = pd.read_csv(\n",
    "    data_food_record, \n",
    "    sep='\\t', \n",
    "    encoding='iso-8859-1')\n",
    "\n",
    "food_animal_percent = pd.read_csv(\n",
    "    data_food_animal_proportion, \n",
    "    index_col='code'\n",
    ").drop(columns=['link'])\n",
    "\n",
    "food_records = food_records.merge(\n",
    "    food_animal_percent, \n",
    "    left_on='Code', \n",
    "    right_index=True, \n",
    "    how='left'\n",
    ")\n",
    "food_records['timestamp'] = pd.to_datetime(\n",
    "    food_records.DaDate + ' ' + food_records.MaTime,\n",
    "    format='%d.%m.%Y %H:%M:%S'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge diet grouping to food records for checks\n",
    "food_records = food_records.merge(\n",
    "    subjects_all[['ID',diet_class]],\n",
    "    on='ID', \n",
    "    how='left'\n",
    ")\n",
    "fltr_is_vegan = (food_records[diet_class] == 'Vegan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_ap = food_records.animal_proportion.isna()\n",
    "if missing_ap.any():\n",
    "    display(food_records[missing_ap])\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate age when food records taken\n",
    "master = pd.read_spss(data_master)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['dob'] = pd.to_datetime(\n",
    "    master.set_index('ID').syntymaaika\n",
    ")\n",
    "df['date_of_first_food_record'] = pd.to_datetime(\n",
    "    food_records.groupby('ID').DaDate.min(),\n",
    "    dayfirst=True\n",
    ")\n",
    "df['age_at_first_food_record'] = df.date_of_first_food_record - df.dob\n",
    "\n",
    "subjects_all = subjects_all.merge(\n",
    "    df.drop(columns=['dob']).reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global settings for graph output\n",
    "scale=10\n",
    "sns.set_theme(style='white',font_scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sanity checking food record lenths\n",
    "df = food_records.groupby('ID').agg({'timestamp': ['min', 'max']})\n",
    "df.columns = ['ts_min','ts_max']\n",
    "df = df.merge(\n",
    "    food_records[['ID','DaDate']].groupby('ID').nunique(),\n",
    "    on='ID'\n",
    ")\n",
    "df.rename(columns = {'DaDate':'record_distinct_dates'}, inplace = True)\n",
    "df.record_distinct_dates.hist(range=(0,6),bins=6)\n",
    "df.to_csv('out/fr_days.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check which food items with nonzero animal content appear for vegans\n",
    "\n",
    "def vegan_animal_consumption():    \n",
    "    return food_records[\n",
    "        (food_records.animal_proportion > 0) \n",
    "        & fltr_is_vegan\n",
    "    ].groupby(['name','MaName']).count()[diet_class]    \n",
    "\n",
    "df = vegan_animal_consumption()\n",
    "df.to_csv('out/vegan_animal_consumption.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average cooking fat present in one recipe (in soy bolognese, Fineli code 28961, in fried onion, Fineli code 3230) \n",
    "# was manually confirmed from the food record to be incorrect\n",
    "# Participant had consumed a sauce that does not contain added fat, unlike the generic sauce which was initially entered. \n",
    "# Average cooking oil was dropped from these two occasions where it had been erroneously entered.\n",
    "\n",
    "fltr = (food_records.name=='Ruoanvalmistusrasva keskiarvo') & (food_records[diet_class]=='Vegan')\n",
    "rows_to_drop = food_records[fltr]\n",
    "idx_to_drop = rows_to_drop.index\n",
    "food_records = food_records.drop(idx_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_ap_for_vegans(ingredient_name):\n",
    "    \n",
    "    fltr = (food_records.name == ingredient_name) & fltr_is_vegan\n",
    "\n",
    "    food_records.loc[fltr,'animal_proportion'] = 0\n",
    "    food_records.loc[fltr,'animal_decile'] = 0\n",
    "\n",
    "    print(f\"{sum(fltr)} food records of vegans consuming '{ingredient_name}' updated to animal_proportion==0\")\n",
    "\n",
    "# Correcting data entry which was confirmed to be a typo: vegetable stock was entered as fish stock.\n",
    "\n",
    "zero_ap_for_vegans('Knorr Kalaliemi, jauhe, vähäsuolainen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vegan_animal_consumption()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate ASE proportion\n",
    "r_animal = 'r_animal_source_energy'\n",
    "r_animal_label = 'Animal source energy proportion'\n",
    "\n",
    "e = food_records[['ID','ENERJ','animal_proportion']]\n",
    "e = e.assign(ENERJ_animal=(e.ENERJ * e.animal_proportion)).drop(columns=['animal_proportion'])\n",
    "\n",
    "#energy per subject\n",
    "eps = e.groupby(['ID']).sum()\n",
    "eps = eps.assign(r_animal_source_energy=(eps.ENERJ_animal / eps.ENERJ))\n",
    "\n",
    "eps.to_csv('out/energy_intake_per_participant.csv')\n",
    "\n",
    "subjects_all = subjects_all.merge(eps, on='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirming zero animal source foods recorded for vegans\n",
    "\n",
    "vegans_nonzero_asep = subjects_all[\n",
    "    (subjects_all[diet_class] == 'Vegan') &\n",
    "    (subjects_all[r_animal] > 0)\n",
    "][r_animal]\n",
    "\n",
    "\n",
    "vegans_nonzero_asep = pd.concat(\n",
    "    [\n",
    "        vegans_nonzero_asep,\n",
    "        vegans_nonzero_asep.describe()\n",
    "    ]\n",
    ")\n",
    "\n",
    "# vegans_nonzero_asep.to_csv('out/vegans_nonzero_asep.csv')\n",
    "display(vegans_nonzero_asep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subject selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data has been manually verified\n",
    "fr_too_short = (105, 405, 801, 802, 119)\n",
    "fr_incomplete_day = (401,)\n",
    "fr_no_weekend = (404,)\n",
    "fr_ill_during_study = (702,)\n",
    "fr_invalid = fr_too_short + fr_incomplete_day + fr_no_weekend + fr_ill_during_study\n",
    "\n",
    "subjects_fr = subjects_all[~subjects_all.ID.isin(fr_invalid)]\n",
    "subjects_ldl = subjects_fr[subjects_fr[ldl].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 1\n",
    "\n",
    "Distribution of the ASE proportions by the diet classification (grouping based on the food records and background questionnaires). Participants' dietary classification is indicated with color coding, with green for vegan, orange for vegetarian and blue for omnivore group. The vegetarian group included lactovegetarians, lacto-ovo-vegetarians and pescovegetarians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"paper\")\n",
    "\n",
    "tricolor_palette=['#55a868','#dd8452','#4c72b0']\n",
    "\n",
    "plt.close()\n",
    "fg = sns.displot(\n",
    "    subjects_fr,\n",
    "    x=r_animal,\n",
    "    binwidth=0.05,\n",
    "    hue=diet_class,\n",
    "    hue_order=diet_classes,\n",
    "    multiple='stack',\n",
    "    height=scale,\n",
    "    palette=tricolor_palette\n",
    ")\n",
    "fg.axes[0,0].set_xlabel(r_animal_label)\n",
    "fg.axes[0,0].set_ylabel('Number of participants')\n",
    "\n",
    "plt.savefig('out/Fig1.svg')\n",
    "plt.savefig('out/Fig1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table 1\n",
    "Describing data with median (min-max)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intakes = [\n",
    "    'ENERJ_per_d',\n",
    "    'ENER_kcal_per_d',\n",
    "    'FAT_e_pros',\n",
    "    'FASAT_e_pros',\n",
    "    'FAMS_e_pros',\n",
    "    'FAPU_e_pros',\n",
    "    'CHOL_per_MJ',\n",
    "    'CHOL_per_d',\n",
    "    'PROT_e_pros',\n",
    "    'CHO_e_pros',\n",
    "    'SUCS_e_pros',\n",
    "    'FIBC_per_MJ',\n",
    "    'FIBC_per_d',\n",
    "    'SALT_per_MJ',\n",
    "    'SALT_per_d',\n",
    "    'FOL_per_d'\n",
    "]\n",
    "biomarkers = [\n",
    "    'fP-Kol (mmol/l)',\n",
    "    'fP-Kol-LDL (mmol/l)',\n",
    "    'fP-Kol-HDL (mmol/l)',\n",
    "    'fP-Trigly (mmol/l)',\n",
    "    'fE-Folaat (nmol/l)'    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(name, df):\n",
    "    count_diet_classes = df[diet_class].value_counts().to_frame()\n",
    "    count_sexes = df.sukupuoli.value_counts().to_frame()\n",
    "    count_bmi_class = df.bmi_class.value_counts().to_frame()\n",
    "    desc_intakes = df[['age_at_first_food_record','bmi_sds']+intakes+biomarkers].describe().transpose()[['50%','min','max']]\n",
    "    \n",
    "    with pd.ExcelWriter(\n",
    "        f'out/summary_{name}.xlsx',\n",
    "        mode='w'\n",
    "    ) as writer:\n",
    "        \n",
    "        count_diet_classes.to_excel(\n",
    "            writer,\n",
    "            sheet_name='diet_classes'\n",
    "        )\n",
    "    \n",
    "        count_sexes.to_excel(\n",
    "            writer,\n",
    "            sheet_name='sexes'\n",
    "        )\n",
    "\n",
    "        count_bmi_class.to_excel(\n",
    "            writer,\n",
    "            sheet_name='bmi_class'\n",
    "        )\n",
    "\n",
    "        desc_intakes.to_excel(\n",
    "            writer,\n",
    "            sheet_name='intakes'\n",
    "        )    \n",
    "    \n",
    "    print(len(df.index))\n",
    "    display(count_diet_classes)\n",
    "    display(count_sexes)\n",
    "    display(count_bmi_class)\n",
    "    display(desc_intakes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize('participants_with_valid_fr', subjects_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize('participants_with_valid_fr_and_blood_sample',subjects_ldl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_values(subjects, xs,ys):\n",
    "    table = []\n",
    "    for x in xs:\n",
    "        for y in ys:\n",
    "            df = subjects[[x,y]].dropna()\n",
    "            n = len(df.index)\n",
    "            pr, pp = pearsonr(df[x],df[y])\n",
    "            sr, sp = spearmanr(df[x],df[y])\n",
    "            table.append([n,x,y,pr,pp,sr,sp])\n",
    "\n",
    "    df = pd.DataFrame(table,columns=['n','x','y','pearson_r','pearson_p','spearman_r','spearman_p'])\n",
    "    df['pearson_bh_0_05'] = multipletests(df['pearson_p'], alpha=0.05, method='fdr_bh')[0]\n",
    "    df['spearman_bh_0_05'] = multipletests(df['spearman_p'], alpha=0.05, method='fdr_bh')[0]\n",
    "    df = df.sort_values(by='pearson_p')\n",
    "    df = df.round(3)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = correlation_values(\n",
    "    subjects_ldl,\n",
    "    [r_animal],\n",
    "    intakes\n",
    ")\n",
    "df.to_csv('out/table2-correlations-ASEP-intakes.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import ascii_lowercase\n",
    "\n",
    "markers=['o','s','^']\n",
    "\n",
    "def regplot_r_animal(df,ax,y,y_label,set_xlabel=True):\n",
    "    \n",
    "    sample = df[['r_animal_source_energy',diet_class,y]].dropna()\n",
    "    \n",
    "    right = sample.r_animal_source_energy.max()\n",
    "    ax.set_xlim(-0.01, right+0.01)\n",
    "    \n",
    "    \n",
    "    #sns.regplot(ax=ax, x=r_animal, y=y, scatter=False, data=df)\n",
    "    sns.scatterplot(\n",
    "        ax=ax, \n",
    "        x=r_animal, \n",
    "        y=y, \n",
    "        hue=diet_class,\n",
    "        hue_order=diet_classes,\n",
    "        style=diet_class,\n",
    "        markers=markers,\n",
    "        data=sample, \n",
    "        s=30*scale,\n",
    "        palette=tricolor_palette,\n",
    "        legend=False\n",
    "    )\n",
    "    if set_xlabel:\n",
    "        ax.set_xlabel(r_animal_label)\n",
    "    else:\n",
    "        ax.set_xlabel(None)\n",
    "    ax.set_ylabel(y_label)\n",
    "    \n",
    "    sr, sp = spearmanr(sample.r_animal_source_energy,sample[y])\n",
    "    \n",
    "    label = f'ρ= {sr:.3f}'\n",
    "    if sr < 0:\n",
    "        ax.text(0.7,0.9, label, transform=ax.transAxes)\n",
    "    elif sr > 0:\n",
    "        ax.text(0.1,0.9, label, transform=ax.transAxes)\n",
    "\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "def splats(n):\n",
    "    return [\n",
    "        Line2D(\n",
    "            [0], \n",
    "            [0], \n",
    "            marker=markers[i],\n",
    "            color='w',\n",
    "            markerfacecolor=tricolor_palette[i],\n",
    "            markersize=15\n",
    "        )\n",
    "        for i in range(0,n)\n",
    "    ]\n",
    "\n",
    "\n",
    "def fig_of_regplots(df,ys,cols):\n",
    "\n",
    "    plt.close()\n",
    "    sns.set_theme(style='white',font_scale=2)\n",
    "    \n",
    "    rows = int(len(ys)/cols)+(len(ys)%cols > 0)\n",
    "    h = rows*scale\n",
    "    if rows > 1: h+=2\n",
    "    w = cols*scale+2\n",
    "    \n",
    "    fig, axs = plt.subplots(rows,cols,figsize=(w,h))\n",
    "        \n",
    "    if rows > 1:\n",
    "        axs_flat = [ax for row in axs for ax in row]\n",
    "    else:\n",
    "        axs_flat = axs\n",
    "\n",
    "    l = list(zip(ys.keys(),ys.values(),axs_flat))\n",
    "    i = 0\n",
    "    for t in l:\n",
    "        ax = t[2]\n",
    "        y = t[0]\n",
    "        regplot_r_animal(df,ax,y,t[1],set_xlabel=False)\n",
    "        i+=1\n",
    "\n",
    "    for ax in axs_flat[len(ys):]:\n",
    "        fig.delaxes(ax)\n",
    "    \n",
    "    if rows*cols > len(ys):\n",
    "        plt.figlegend(splats(3),diet_classes,bbox_to_anchor=((1.09-1/cols),1.03/rows))        \n",
    "    else:\n",
    "        plt.figlegend(splats(3),diet_classes)\n",
    "\n",
    "    \n",
    "    return fig, axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"paper\")\n",
    "\n",
    "ys = {\n",
    "    'PROT_e_pros': 'Protein intake (E%)',\n",
    "    'FIBC_per_MJ': 'Fiber intake (g/MJ)',\n",
    "    'FOL_per_d': 'Folate intake (µg/d)',\n",
    "    'FASAT_e_pros': 'Saturated Fat intake (E%)',\n",
    "    'FAPU_e_pros': 'Polyunsaturated Fat intake (E%)',\n",
    "    'CHOL_per_MJ': 'Cholesterol intake (mg/MJ)',\n",
    "    'fP-Kol-LDL (mmol/l)': 'LDL cholesterol intake (mmol/l)',\n",
    "    'fE-Folaat (nmol/l)': 'Erythrocyte folate intake (nmol/l)'  \n",
    "}\n",
    "\n",
    "fig, axs = fig_of_regplots(subjects_fr,ys,3)\n",
    "\n",
    "plt.savefig('out/Fig3.svg')\n",
    "plt.savefig('out/Fig3.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Readable versions of source data\n",
    "Write excel files to /out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_all.to_excel('out/subjects_all.xlsx')\n",
    "food_records.to_excel('out/food_records.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
